{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement a convolutional neural network (CNN) in PyTorch that processes 32×32 RGB images and defines a custom loss function. Your implementation must use the exact variable and function names given below so that the autograder can verify your solution automatically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "       +---------------------+\n",
    "       |  Input: 32×32×3     |\n",
    "       +----------+----------+\n",
    "                  |\n",
    "                  v\n",
    "       +---------------------+\n",
    "       | Conv1: 3×3, s=1,    |\n",
    "       | no padding, 32 ch   |\n",
    "       | Output: 30×30×32    |\n",
    "       +----------+----------+\n",
    "                  |\n",
    "                  v\n",
    "       +---------------------+\n",
    "       | MaxPool1: 2×2, s=2  |\n",
    "       | Output: 15×15×32    |\n",
    "       +----------+----------+\n",
    "                  |\n",
    "                  v\n",
    "       +---------------------+\n",
    "       | Conv2: 3×3, s=1,    |\n",
    "       | no padding, 64 ch   |\n",
    "       | Output: 13×13×64    |\n",
    "       +----------+----------+\n",
    "                  |\n",
    "                  v\n",
    "       +---------------------+\n",
    "       | MaxPool2: 2×2, s=2  |\n",
    "       | Output: 6×6×64      |\n",
    "       +----------+----------+\n",
    "                  |\n",
    "                  v\n",
    "       +---------------------+\n",
    "       | Flatten             |\n",
    "       | (6×6×64 = 2304)     |\n",
    "       +----------+----------+\n",
    "                  |\n",
    "                  v\n",
    "       +---------------------+\n",
    "       | Fully Connected     |\n",
    "       | 2304 → 10           |\n",
    "       +---------------------+"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Network Architecture\n",
    "\n",
    "Implement a CNN with the following specifications:\n",
    "Input:\n",
    "\n",
    "Images of size 32×32 with 3 channels (RGB).\n",
    "Block 1:\n",
    "\n",
    "Convolutional Layer (conv1):\n",
    "kernel_size: 3×3\n",
    "stride: 1\n",
    "padding: 0 (i.e. no padding)\n",
    "in_channels: 3\n",
    "out_channels: 32\n",
    "Max-Pooling Layer (pool):\n",
    "kernel_size: 2\n",
    "stride: 2\n",
    "Block 2:\n",
    "\n",
    "Convolutional Layer (conv2):\n",
    "kernel_size: 3×3\n",
    "stride: 1\n",
    "padding: 0\n",
    "Output channels: 64\n",
    "Max-Pooling Layer (pool):\n",
    "kernel_size: 2\n",
    "stride: 2\n",
    "Fully Connected Layer (fc):\n",
    "\n",
    "After the two convolution+pooling blocks, flatten the output and add a fully connected layer that maps the flattened features to 10 output classes.\n",
    "forward Method\n",
    "\n",
    "Your forward method should perform the following steps exactly:\n",
    "\n",
    "    Apply ReLU activation after each convolution.\n",
    "    Use the pooling layer after each convolution block.\n",
    "    Flatten the output before passing it to the fully connected layer.\n",
    "    Finally, produce the logits via the fully connected layer.\n",
    "\n",
    "Variable Name for the Model:\n",
    "\n",
    "The final model must be stored in a variable called myModel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCNN(nn.Module):\n",
    "    def __init__(self, num_classes=10, input_size=32):\n",
    "        \"\"\"\n",
    "        Constructs a CNN with two convolution+maxpool blocks followed by a fully connected layer.\n",
    "        \n",
    "        Specifications:\n",
    "          - Input: images of size 32x32 with 3 channels.\n",
    "          - Block 1:\n",
    "              * Conv layer with kernel_size 3x3, stride 1, no padding, output channels = 32.\n",
    "              * MaxPool layer with kernel size 2, stride 2.\n",
    "          - Block 2:\n",
    "              * Conv layer with kernel_size 3x3, stride 1, no padding, output channels = 64.\n",
    "              * MaxPool layer with kernel size 2, stride 2.\n",
    "          - Flatten the features and apply a fully connected layer mapping to output size 10.\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        super(MyCNN,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels = 3, out_channels = 32, kernel_size = 3, stride = 1, padding = 0)\n",
    "        self.pool = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "        self.conv2 = nn.Conv2d(in_channels = 32, out_channels = 64, kernel_size = 3, stride = 1, padding = 0)\n",
    "\n",
    "        self.fc = nn.Linear(6*6*64,num_classes)\n",
    "        #raise NotImplementedError()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # YOUR CODE HERE\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(x.size(0),-1)\n",
    "        x = self.fc(x)\n",
    "        # raise NotImplementedError()\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final model should be stored in the variable 'myModel'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myModel = MyCNN(num_classes=10, input_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Loss Function\n",
    "\n",
    "Define a custom loss function that meets the following criteria:\n",
    "\n",
    "Function Name:\n",
    "\n",
    "The function must be named LF. Function Arguments:\n",
    "\n",
    "The function should take three parameters: the model's output (logits), the target labels, and the model itself. Function Behavior:\n",
    "\n",
    "Compute the standard cross-entropy loss between the output and the target. Add an L2 regularization term calculated as the sum of squared L2 norms of all the model's parameters. The regularization term must be scaled by a factor of 0.1. The function must return a scalar tensor representing the combined loss. Variable Name for the Loss Function:\n",
    "\n",
    "The loss function must be stored in a variable called LF (i.e. the function name is LF)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LF(output, target, model):\n",
    "    \"\"\"\n",
    "    Return:\n",
    "        Tensor: Scalar loss value.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    loss = F.cross_entropy(output,target)\n",
    "    l2_reg = sum(torch.sum(param** 2) for param in model.parameters())\n",
    "    return loss + 0.1*l2_reg\n",
    "    # raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the total_params value with total number of trainable parameters in the notebook in the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# total_params = sum(p.numel() for p in myModel.parameters() if p.requires_grad)\n",
    "total_params = 42442\n",
    "# raise NotImplementedError()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
