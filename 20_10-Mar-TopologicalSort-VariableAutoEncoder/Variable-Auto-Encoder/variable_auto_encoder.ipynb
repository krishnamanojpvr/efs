{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement\n",
    "In this notebook, you will implement a Variational Autoencoder (VAE) using PyTorch.\n",
    "\n",
    "### Tasks:\n",
    "1. Implement the Encoder network to produce mean and log-variance.\n",
    "2. Implement the Reparameterization Trick.\n",
    "3. Implement the Decoder network to reconstruct images.\n",
    "4. Implement the VAE loss function.\n",
    "5. Train the VAE using the Adam optimizer.\n",
    "6. Generate and visualize new images from random latent vectors.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                         +-------------------------+\n",
    "                         |        Input x          |\n",
    "                         |    (Flattened Image)    |\n",
    "                         +-------------------------+\n",
    "                                     |\n",
    "                                     v\n",
    "                         +-------------------------+\n",
    "                         |        Encoder          |\n",
    "                         |  Linear(784 → 400)      |\n",
    "                         |         ReLU            |\n",
    "                         +-------------------------+\n",
    "                                     |\n",
    "                                     v\n",
    "                  +--------------------------------------+\n",
    "                  |      Mean (μ)       |    Log-Var    |\n",
    "                  |  Linear(400 → 20)   | Linear(400 → 20) |\n",
    "                  +--------------------------------------+\n",
    "                                     |  |\n",
    "                                     |  |\n",
    "                                     v  v\n",
    "                         +-------------------------+\n",
    "                         |  Compute std = exp(0.5 * logvar) |\n",
    "                         |  Sample eps ~ N(0,1)           |\n",
    "                         |  Compute z = μ + eps * std     |\n",
    "                         +-------------------------+\n",
    "                                     |\n",
    "                                     v\n",
    "                         +-------------------------+\n",
    "                         |        Decoder          |\n",
    "                         |  Linear(20 → 400)       |\n",
    "                         |         ReLU            |\n",
    "                         |  Linear(400 → 784)      |\n",
    "                         |       Sigmoid          |\n",
    "                         +-------------------------+\n",
    "                                     |\n",
    "                                     v\n",
    "                         +-------------------------+\n",
    "                         |   Reconstructed Image   |\n",
    "                         +-------------------------+\n",
    "                                     |\n",
    "                                     v\n",
    "                         +-------------------------+\n",
    "                         |        Loss Function    |\n",
    "                         |  Reconstruction Loss    |\n",
    "                         |  Binary Cross-Entropy   |\n",
    "                         |                         |\n",
    "                         |   KL Divergence Loss    |\n",
    "                         | D_KL(q(z|x) || p(z))    |\n",
    "                         +-------------------------+\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the VAE model\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, latent_dim=20):\n",
    "        super(VAE, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(784,400),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # write the code for Mean and Log-variance\n",
    "        # YOUR CODE HERE\n",
    "        self.fc_mu = nn.Linear(400,20)\n",
    "        self.fc_logvar = nn.Linear(400,20) \n",
    "        \n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "           nn.Linear(20,400),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(400,784),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def encode(self, x):\n",
    "        x = self.encoder(x)\n",
    "        mu = self.fc_mu(x)\n",
    "        logvar = self.fc_logvar(x)\n",
    "        return mu, logvar\n",
    "    \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        \"\"\"Reparameterization Trick\"\"\"\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "    \n",
    "    def decode(self, z):\n",
    "        return self.decoder(z)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decode(z), mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "def vae_loss(reconstructed_x, x, mu, logvar):\n",
    "    reconstruction_loss = F.binary_cross_entropy(reconstructed_x,x,reduction='sum')\n",
    "    kl_divergence = 0.5*torch.sum(1+logvar-mu.pow(2)-logvar.exp())\n",
    "    return reconstruction_loss + kl_divergence\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset from 'generated_images' directory\n",
    "DATASET_PATH = \"/srv/shareddata/datasets/course101/minst-data-vae\"\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),  # Ensure grayscale images like MNIST\n",
    "    transforms.ToTensor(),  # Convert image to tensor\n",
    "    transforms.Lambda(lambda x: x.view(-1))  # Flatten to match MNIST format (1, 28, 28) -> (784,)\n",
    "])\n",
    "\n",
    "# Use DatasetFolder to load images without requiring subdirectories\n",
    "train_dataset = datasets.DatasetFolder(root=DATASET_PATH, loader=lambda x: Image.open(x).convert(\"L\"), extensions=('png', 'jpg', 'jpeg'), transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "vae = VAE(latent_dim=20).to(device)\n",
    "optimizer = optim.Adam(vae.parameters(), lr=1e-3)\n",
    "\n",
    "num_epochs = 3\n",
    "for epoch in range(num_epochs):\n",
    "    vae.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, (data, _) in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        reconstructed_x, mu, logvar = vae(data)\n",
    "        loss = vae_loss(reconstructed_x, data, mu, logvar)\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {train_loss / len(train_loader.dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate new images\n",
    "vae.eval()\n",
    "with torch.no_grad():\n",
    "    z = torch.randn(16, 20).to(device)  # Sample random latent vectors\n",
    "    samples = vae.decode(z).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot generated images\n",
    "fig, axes = plt.subplots(4, 4, figsize=(5, 5))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(samples[i].reshape(28, 28), cmap='gray')\n",
    "    ax.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
